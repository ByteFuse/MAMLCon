{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly_express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/training_results.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m../data/training_results.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\ruanv\\miniconda3\\envs\\flickr2\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ruanv\\miniconda3\\envs\\flickr2\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\ruanv\\miniconda3\\envs\\flickr2\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\ruanv\\miniconda3\\envs\\flickr2\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\ruanv\\miniconda3\\envs\\flickr2\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m     f,\n\u001b[0;32m   1219\u001b[0m     mode,\n\u001b[0;32m   1220\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1221\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1222\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1223\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1224\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1225\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1226\u001b[0m )\n\u001b[0;32m   1227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\ruanv\\miniconda3\\envs\\flickr2\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    790\u001b[0m             handle,\n\u001b[0;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    792\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    793\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    794\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    795\u001b[0m         )\n\u001b[0;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/training_results.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/training_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.n_way==10 )& (df.dataset=='flickr8k')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df_1 = df[(df.n_way==50)&(df.n_class_additions==5)&(df.n_classes_start==5)&(df.algorithm=='FSCL')&(df.dataset=='flickr8k')].\\\n",
    "    drop(columns=['Name']).groupby(['k_shot']).max().reset_index(drop=False)\n",
    "plot_df_2 = df[(df.n_way==10)&(df.n_class_additions==1)&(df.n_classes_start==2)&(df.algorithm=='FSCL')&(df.dataset=='google_commands')].\\\n",
    "    drop(columns=['Name']).groupby(['k_shot']).max().reset_index(drop=False)\n",
    "plot_df = pd.concat([plot_df_1, plot_df_2])\n",
    "\n",
    "def rename_(name):\n",
    "    if name == 'flickr8k':\n",
    "        return 'Flickr8k: N=50, CA=5, CS=5'\n",
    "    else:\n",
    "        return \"Google Commands: N=10, CA=2, CS=2\"\n",
    "\n",
    "plot_df['dataset']=plot_df['dataset'].apply(rename_)\n",
    "plot_df.rename(columns={'k_shot':'K-Shot', 'validation_query_accuracy_epoch':'Final Accuracy', 'dataset':'Dataset'}, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "# set colours allowed to use to certain hex value\n",
    "sns.set_palette(sns.color_palette([\"#1D2140\", \"#17C37B\"])) \n",
    "sns.barplot(x='K-Shot', y='Final Accuracy', hue='Dataset', data=plot_df)\n",
    "#add the value on top of the bar\n",
    "for p in plt.gca().patches:\n",
    "    plt.gca().text(p.get_x() + p.get_width()/2., p.get_height(), '{:1.2f}'.format(p.get_height()*100), fontsize=18, color='black', ha='center', va='bottom')\n",
    "\n",
    "# make the legend text bigger\n",
    "plt.legend(loc='lower right', prop={'size': 20})\n",
    "# make plot font size bigger\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "# remove top grid line\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "plt.savefig('k_shot_accuracy.png', transparent=True, pad_inches=.2, frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate CL insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ruanv\\miniconda3\\envs\\flickr2\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\ruanv\\miniconda3\\envs\\flickr2\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from src.models import WordClassificationAudio2DCnn, WordClassificationAudioCnnPool as WordClassificationAudioCnn, WordClassificationRnn\n",
    "from src.losses import ClassificationLoss\n",
    "from src.algorithms import FSCL, OML\n",
    "from src.data.datasets import Flickr8kWordClassification, GoogleCommandsWordClassification\n",
    "from src.data.samplers import SpokenWordTaskBatchSampler\n",
    "from src.utils import flatten_dict\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ruanv\\AppData\\Local\\Temp\\ipykernel_12636\\1303192644.py:27: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(layer.weight, )\n"
     ]
    }
   ],
   "source": [
    "optim = {\n",
    "'name': 'adam',\n",
    "'inner_steps': 5,\n",
    "'val_inner_steps': 5,\n",
    "'gradient_clip_val': 0,\n",
    "'inner_learning_rate': 0.001,\n",
    "'outer_learning_rate': 0.0001,\n",
    "'scheduler': False,\n",
    "'scheduler_step': 30,\n",
    "'scheduler_decay': 0.1,\n",
    "}\n",
    "\n",
    "encoder = WordClassificationAudio2DCnn(\n",
    "    256, \n",
    "    64, \n",
    "    input_channels=39\n",
    ")\n",
    "\n",
    "class FSCLModel(nn.Module):\n",
    "    def __init__(self, encoder, embedding_dim, n_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "\n",
    "        def return_classification_layer(embedding_dim):\n",
    "            layer = nn.Linear(embedding_dim, 1)\n",
    "            torch.nn.init.xavier_uniform(layer.weight, )\n",
    "            layer = nn.Sequential(\n",
    "                nn.ReLU(),\n",
    "                layer\n",
    "            )\n",
    "            return layer\n",
    "\n",
    "        layers = [return_classification_layer(embedding_dim) for _ in range(n_classes)]\n",
    "        self.classifiers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, audio, total_classes_present):\n",
    "        features = self.encoder(audio)\n",
    "        layer_logits = []\n",
    "        for c_layer in range(total_classes_present):\n",
    "            layer_logits.append(self.classifiers[c_layer](features))\n",
    "        logits = torch.cat(layer_logits, dim=1)\n",
    "        return {'logits':logits}\n",
    "\n",
    "\n",
    "loss_fn = ClassificationLoss()\n",
    "\n",
    "model = FSCLModel(encoder, 256, 50)\n",
    "algorithm = FSCL.load_from_checkpoint(\n",
    "    './nway50_k5.ckpt', \n",
    "    model=model, \n",
    "    training_steps=5,\n",
    "    intial_training_steps=30,\n",
    "    n_classes_start=5,\n",
    "    n_class_additions=5,\n",
    "    loss_func=loss_fn,\n",
    "    optim_config=optim,\n",
    "    k_shot=5,\n",
    "    quick_adapt=True\n",
    ")\n",
    "model = algorithm.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/ruanv/Desktop/speech-fewshot-cl/data/flickr/flickr8k_word_splits_validation.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading audio: 100%|██████████| 32974/32974 [00:00<00:00, 375589.59it/s]\n",
      "Loading audio: 100%|██████████| 250/250 [00:00<00:00, 252304.14it/s]\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "with open('../config/conversion_method/mfcc.yaml') as f:\n",
    "    conv_config = yaml.safe_load(f) \n",
    "\n",
    "valiadation_dataset = Flickr8kWordClassification(\n",
    "    meta_path='C:/Users/ruanv/Desktop/speech-fewshot-cl/data/flickr/flickr8k_word_splits_validation.csv',\n",
    "    audio_root='C:/Users/ruanv/Desktop/speech-fewshot-cl/data/flickr/wavs/', \n",
    "    conversion_config=conv_config,\n",
    "    stemming=True, \n",
    "    lemmetise=False          \n",
    ")\n",
    "\n",
    "\n",
    "def pad_audio(x, max_audio_len=101, pad_both_sides=False):\n",
    "    import torch.nn.functional as F\n",
    "    if x.size(-1) > max_audio_len:\n",
    "        x = x[:,:max_audio_len]\n",
    "    else:\n",
    "        if pad_both_sides:\n",
    "            pad_lenght = int(max_audio_len-x.size(-1))//2\n",
    "            x = F.pad(x, (pad_lenght, pad_lenght+1 if int(max_audio_len-x.size(-1))%2!=0 else pad_lenght), 'constant', 0)\n",
    "        else:\n",
    "            x = F.pad(x, (0, int(max_audio_len-x.size(-1))), 'constant', 0)\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = [5,10]\n",
    "K_SHOT = [5,10,20,50]\n",
    "UPDATES = [True, False]\n",
    "\n",
    "LR = 0.0001\n",
    "N_TRAINING_STEPS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5 True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading audio: 100%|██████████| 250/250 [00:00<00:00, 251819.40it/s]\n",
      "C:\\Users\\ruanv\\AppData\\Local\\Temp\\ipykernel_12636\\1303192644.py:27: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(layer.weight, )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5 False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading audio: 100%|██████████| 250/250 [00:00<00:00, 250675.59it/s]\n",
      "C:\\Users\\ruanv\\AppData\\Local\\Temp\\ipykernel_12636\\1303192644.py:27: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(layer.weight, )\n"
     ]
    }
   ],
   "source": [
    "for N in N_CLASSES:\n",
    "    for K in K_SHOT:\n",
    "        for UPDATE in UPDATES:\n",
    "\n",
    "            print(N, K, UPDATE)\n",
    "\n",
    "            df = pd.read_csv('C:/Users/ruanv/Desktop/speech-fewshot-cl/data/flickr/flickr8k_word_splits_validation.csv')\n",
    "            words_keep = [\n",
    "            'surf', 'wave', 'crowd', 'fight', 'togeth', 'ski',\n",
    "            'bridg', 'wood', 'teenag', 'lot', 'mud', 'pool', 'tabl', 'out',\n",
    "            'wet', 'footbal', 'make', 'team', 'shop', 'their', 'edg', 'guitar',\n",
    "            'across', 'area', 'do', 'trick', 'bike', 'obstacl', 'tri', 'rider',\n",
    "            'track', 'room', 'him', 'jacket', 'glass', 'open', 'them', 'cap',\n",
    "            'color', 'set', 'pant', 'wrestl', 'basketbal', 'climber', 'face',\n",
    "            'mountain', 'tent', 'shore', 'ground', 'bar'\n",
    "            ]\n",
    "            df = df[df.stem.isin(words_keep)]\n",
    "\n",
    "            # sample 5 instances of each stem\n",
    "            df = df.groupby('stem').apply(lambda x: x.sample(K)).reset_index(drop=True)\n",
    "            df.to_csv('./plot_data_words.csv', index=False)\n",
    "\n",
    "\n",
    "            valiadation_dataset = Flickr8kWordClassification(\n",
    "                meta_path='plot_data_words.csv',\n",
    "                audio_root='C:/Users/ruanv/Desktop/speech-fewshot-cl/data/flickr/wavs/', \n",
    "                conversion_config=conv_config,\n",
    "                stemming=True, \n",
    "                lemmetise=False          \n",
    "            )\n",
    "\n",
    "            file_name = f'nway{N}_k{K}_update{UPDATE}_MAMLCON.csv'\n",
    "\n",
    "            STEPS = K*N\n",
    "\n",
    "\n",
    "            groups = []\n",
    "            test_groups = []\n",
    "\n",
    "            for i in range(0, len(valiadation_dataset), STEPS):\n",
    "                arrays = []\n",
    "                labels = []\n",
    "\n",
    "                for j in range(0+i, STEPS+i):\n",
    "                    arrays.append(pad_audio(torch.tensor(valiadation_dataset[j][0])).unsqueeze(0))\n",
    "                    labels.append(torch.tensor(valiadation_dataset[j][1]))\n",
    "                \n",
    "                arrays = torch.concat(arrays,dim=0)\n",
    "\n",
    "                # take every 5th instance as test\n",
    "                test_arrays = arrays[::N]\n",
    "                test_labels = labels[::N]\n",
    "\n",
    "                # skip every 5th instance\n",
    "                arrays = torch.concat([array.unsqueeze(0) for i, array in enumerate(arrays) if i%N!=0 or i==0],dim=0)\n",
    "                labels = [label for i, label in enumerate(labels) if i%N!=0 or i==0]\n",
    "\n",
    "                groups.append({'data':arrays, 'labels':labels})\n",
    "                test_groups.append({'data':test_arrays, 'labels':test_labels})\n",
    "\n",
    "            results = pd.DataFrame()\n",
    "\n",
    "            model = FSCLModel(encoder, 256, 50)\n",
    "            algorithm = FSCL.load_from_checkpoint(\n",
    "                './nway50_k5.ckpt', \n",
    "                model=model, \n",
    "                training_steps=5,\n",
    "                intial_training_steps=30,\n",
    "                n_classes_start=5,\n",
    "                n_class_additions=5,\n",
    "                loss_func=loss_fn,\n",
    "                optim_config=optim,\n",
    "                k_shot=5,\n",
    "                quick_adapt=True\n",
    "            )\n",
    "            model = algorithm.model\n",
    "\n",
    "            criterion = ClassificationLoss()\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "            # Training loop\n",
    "            for n, group in enumerate(groups):\n",
    "                model.train()\n",
    "                data, labels = group['data'], group['labels']\n",
    "                for i in range(N_TRAINING_STEPS):\n",
    "                    # Clear gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # Forward pass\n",
    "                    outputs = model(data, (n+1)*N)\n",
    "                    outputs['labels'] = torch.tensor(labels)\n",
    "                    # Compute loss\n",
    "                    loss = criterion(outputs)\n",
    "                    \n",
    "                    # Backward pass and optimization\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                        \n",
    "                # Print loss for each epoch\n",
    "                # print(f'Training loss: {loss.item():.4f}')\n",
    "\n",
    "                if UPDATE:\n",
    "\n",
    "                    for group in groups[:n+1]:\n",
    "                        data, labels = group['data'], group['labels']\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        # take every 5th instance\n",
    "                        data = data[::5]\n",
    "                        labels = labels[::5]\n",
    "\n",
    "                        # Forward pass\n",
    "                        outputs = model(data, (n+1)*N)\n",
    "                        outputs['labels'] = torch.tensor(labels)\n",
    "                        # Compute loss\n",
    "                        loss = criterion(outputs)\n",
    "                        \n",
    "                        # Backward pass and optimization\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "\n",
    "                    for i, group in enumerate(test_groups[:n+1]):\n",
    "                        data, labels = group['data'], group['labels']\n",
    "                        outputs = model(data, (i+1)*N)\n",
    "                        outputs['labels'] = torch.tensor(labels)\n",
    "                        loss = criterion(outputs)\n",
    "\n",
    "                        predicted_labels = torch.argmax(outputs['logits'], dim=1)\n",
    "                        accuracy = torch.sum(predicted_labels == torch.tensor(labels)).item() / len(labels)\n",
    "\n",
    "                        results = pd.concat([results,pd.DataFrame({'loss':[loss.item()], 'accuracy':[accuracy], 'group':[i], 'training_group':[n]})])\n",
    "                        results.to_csv(file_name, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in N_CLASSES:\n",
    "    for K in K_SHOT:\n",
    "        for UPDATE in UPDATES:\n",
    "\n",
    "            df = pd.read_csv('C:/Users/ruanv/Desktop/speech-fewshot-cl/data/flickr/flickr8k_word_splits_validation.csv')\n",
    "            words_keep = [\n",
    "            'surf', 'wave', 'crowd', 'fight', 'togeth', 'ski',\n",
    "            'bridg', 'wood', 'teenag', 'lot', 'mud', 'pool', 'tabl', 'out',\n",
    "            'wet', 'footbal', 'make', 'team', 'shop', 'their', 'edg', 'guitar',\n",
    "            'across', 'area', 'do', 'trick', 'bike', 'obstacl', 'tri', 'rider',\n",
    "            'track', 'room', 'him', 'jacket', 'glass', 'open', 'them', 'cap',\n",
    "            'color', 'set', 'pant', 'wrestl', 'basketbal', 'climber', 'face',\n",
    "            'mountain', 'tent', 'shore', 'ground', 'bar'\n",
    "            ]\n",
    "            df = df[df.stem.isin(words_keep)]\n",
    "\n",
    "            # sample 5 instances of each stem\n",
    "            df = df.groupby('stem').apply(lambda x: x.sample(K)).reset_index(drop=True)\n",
    "            df.to_csv('./plot_data_words.csv', index=False)\n",
    "\n",
    "\n",
    "            valiadation_dataset = Flickr8kWordClassification(\n",
    "                meta_path='plot_data_words.csv',\n",
    "                audio_root='C:/Users/ruanv/Desktop/speech-fewshot-cl/data/flickr/wavs/', \n",
    "                conversion_config=conv_config,\n",
    "                stemming=True, \n",
    "                lemmetise=False          \n",
    "            )\n",
    "\n",
    "            file_name = f'nway{N}_k{K}_update{UPDATE}.csv'\n",
    "\n",
    "            STEPS = K*N\n",
    "\n",
    "\n",
    "            groups = []\n",
    "            test_groups = []\n",
    "\n",
    "            for i in range(0, len(valiadation_dataset), STEPS):\n",
    "                arrays = []\n",
    "                labels = []\n",
    "\n",
    "                for j in range(0+i, STEPS+i):\n",
    "                    arrays.append(pad_audio(torch.tensor(valiadation_dataset[j][0])).unsqueeze(0))\n",
    "                    labels.append(torch.tensor(valiadation_dataset[j][1]))\n",
    "                \n",
    "                arrays = torch.concat(arrays,dim=0)\n",
    "\n",
    "                # take every 5th instance as test\n",
    "                test_arrays = arrays[::N]\n",
    "                test_labels = labels[::N]\n",
    "\n",
    "                # skip every 5th instance\n",
    "                arrays = torch.concat([array.unsqueeze(0) for i, array in enumerate(arrays) if i%N!=0 or i==0],dim=0)\n",
    "                labels = [label for i, label in enumerate(labels) if i%N!=0 or i==0]\n",
    "\n",
    "                groups.append({'data':arrays, 'labels':labels})\n",
    "                test_groups.append({'data':test_arrays, 'labels':test_labels})\n",
    "\n",
    "            results = pd.DataFrame()\n",
    "\n",
    "            model = FSCLModel(encoder, 256, 50)\n",
    "            criterion = ClassificationLoss()\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "            # Training loop\n",
    "            for n, group in enumerate(groups):\n",
    "                model.train()\n",
    "                data, labels = group['data'], group['labels']\n",
    "                for i in range(N_TRAINING_STEPS):\n",
    "                    # Clear gradients\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    # Forward pass\n",
    "                    outputs = model(data, (n+1)*N)\n",
    "                    outputs['labels'] = torch.tensor(labels)\n",
    "                    # Compute loss\n",
    "                    loss = criterion(outputs)\n",
    "                    \n",
    "                    # Backward pass and optimization\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                        \n",
    "                # Print loss for each epoch\n",
    "                print(f'Training loss: {loss.item():.4f}')\n",
    "\n",
    "                if UPDATE:\n",
    "\n",
    "                    for group in groups[:n+1]:\n",
    "                        data, labels = group['data'], group['labels']\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        # take every 5th instance\n",
    "                        data = data[::5]\n",
    "                        labels = labels[::5]\n",
    "\n",
    "                        # Forward pass\n",
    "                        outputs = model(data, (n+1)*N)\n",
    "                        outputs['labels'] = torch.tensor(labels)\n",
    "                        # Compute loss\n",
    "                        loss = criterion(outputs)\n",
    "                        \n",
    "                        # Backward pass and optimization\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "\n",
    "                    for i, group in enumerate(test_groups[:n+1]):\n",
    "                        data, labels = group['data'], group['labels']\n",
    "                        outputs = model(data, (i+1)*N)\n",
    "                        outputs['labels'] = torch.tensor(labels)\n",
    "                        loss = criterion(outputs)\n",
    "\n",
    "                        predicted_labels = torch.argmax(outputs['logits'], dim=1)\n",
    "                        accuracy = torch.sum(predicted_labels == torch.tensor(labels)).item() / len(labels)\n",
    "\n",
    "                        results = pd.concat([results,pd.DataFrame({'loss':[loss.item()], 'accuracy':[accuracy], 'group':[i], 'training_group':[n]})])\n",
    "                        results.to_csv(file_name, index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate CL insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.DataFrame()\n",
    "\n",
    "import os\n",
    "for file in os.listdir('./'):\n",
    "    if file.endswith('.csv'):\n",
    "        if 'N10' in file:\n",
    "            N=10\n",
    "        else:\n",
    "            N=5\n",
    "        \n",
    "        if 'no_update' in file:\n",
    "            quick_adapt = False\n",
    "        else:\n",
    "            quick_adapt = True\n",
    "\n",
    "        if 'MAML' in file:\n",
    "            MAML = True\n",
    "        else:\n",
    "            MAML = False\n",
    "        \n",
    "        data = pd.read_csv(file)\n",
    "        data['N'] = N\n",
    "        data['quick_adapt'] = quick_adapt\n",
    "        data['MAMLCon'] = MAML\n",
    "        all_data = pd.concat([all_data, data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make four plots\n",
    "# 1. N=5, MAMLCon, quick_adapt\n",
    "# 2. N=5, MAMLCon, no_quick_adapt\n",
    "# 3. N=10, MAMLCon, quick_adapt\n",
    "# 4. N=10, MAMLCon, no_quick_adapt\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.barplot(x='group', y='accuracy', hue='training_group', data=all_data[(all_data['N']==5) & (all_data['MAMLCon']==True) & (all_data['quick_adapt']==True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subplots with two rows and two columns\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# make four subplots, one for MAMLCon and one for MAML\n",
    "plt.figure(figsize=(25,20))\n",
    "\n",
    "# set seaborn colour sceheme\n",
    "sns.set_palette('colorblind')\n",
    "\n",
    "# sns.set_palette()\n",
    "\n",
    "ax1 = plt.subplot(221)\n",
    "ax3 = plt.subplot(222)\n",
    "ax2 = plt.subplot(223)\n",
    "ax4 = plt.subplot(224)\n",
    "\n",
    "plot_1_data = all_data[(all_data['MAMLCon']==True)&(all_data['quick_adapt']==True)&(all_data['N']==5)]\n",
    "g1=sns.barplot(x='group', y='accuracy', hue='training_group', data=plot_1_data, ax=ax1)\n",
    "# put line plot on top of ax1 bar plot of average accuracy of each group\n",
    "sns.lineplot(x='group', y='accuracy', data=plot_1_data.groupby('group').mean(), ax=ax1, color='black', linewidth=3)\n",
    "\n",
    "plot_2_data = all_data[(all_data['MAMLCon']==False)&(all_data['quick_adapt']==True)&(all_data['N']==5)]\n",
    "g2=sns.barplot(x='group', y='accuracy', hue='training_group', data=plot_2_data, ax=ax2)\n",
    "sns.lineplot(x='group', y='accuracy', data=plot_2_data.groupby('group').mean(), ax=ax2, color='black', linewidth=3, label='Average Accuracy')\n",
    "\n",
    "g1.legend_.remove()\n",
    "g2.legend_.remove()\n",
    "\n",
    "# set titles\n",
    "ax1.set_title('MAMLCon')\n",
    "ax2.set_title('Normal Model')\n",
    "\n",
    "# remove top and right spines\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "\n",
    "\n",
    "plot_3_data = all_data[(all_data['MAMLCon']==True)&(all_data['quick_adapt']==False)&(all_data['N']==5)]\n",
    "g3=sns.barplot(x='group', y='accuracy', hue='training_group', data=plot_3_data, ax=ax3)\n",
    "sns.lineplot(x='group', y='accuracy', data=plot_3_data.groupby('group').mean(), ax=ax3, color='black', linewidth=3)\n",
    "\n",
    "plot_4_data = all_data[(all_data['MAMLCon']==False)&(all_data['quick_adapt']==True)&(all_data['N']==5)]\n",
    "g4=sns.barplot(x='group', y='accuracy', hue='training_group', data=plot_4_data, ax=ax4)\n",
    "sns.lineplot(x='group', y='accuracy', data=plot_4_data.groupby('group').mean(), ax=ax4, color='black', linewidth=3, label='Average Accuracy')\n",
    "\n",
    "g3.legend_.remove()\n",
    "g4.legend_.remove()\n",
    "\n",
    "# set titles\n",
    "ax3.set_title('MAMLCon - No quick update')\n",
    "ax4.set_title('Normal Model - No quick update')\n",
    "\n",
    "# set all x labels to be blank\n",
    "ax1.set_xlabel('Class Group')\n",
    "ax2.set_xlabel('Class Group')\n",
    "ax3.set_xlabel('Class Group')\n",
    "ax4.set_xlabel('Class Group')\n",
    "\n",
    "# set all x labels to be blank\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax3.set_ylabel('Accuracy')\n",
    "ax4.set_ylabel('Accuracy')\n",
    "\n",
    "\n",
    "# remove top and right spines\n",
    "ax3.spines['top'].set_visible(False)\n",
    "ax3.spines['right'].set_visible(False)\n",
    "ax4.spines['top'].set_visible(False)\n",
    "ax4.spines['right'].set_visible(False)\n",
    "\n",
    "\n",
    "# make plot font size bigger\n",
    "\n",
    "# put legend outside of plot\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title='Total Groups Trained', prop={'size': 10})\n",
    "\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "\n",
    "# sup title closer to plots\n",
    "plt.suptitle(\"Group Accuracies After Training Other Groups\", y=0.95)\n",
    "\n",
    "plt.savefig('group_accuracies.png', transparent=True, pad_inches=.2, frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_1_data = all_data[(all_data['MAMLCon']==True)&(all_data['quick_adapt']==True)&(all_data['N']==5)]\n",
    "\n",
    "plot_2_data = all_data[(all_data['MAMLCon']==False)&(all_data['quick_adapt']==True)&(all_data['N']==5)]\n",
    "\n",
    "plot_3_data = all_data[(all_data['MAMLCon']==True)&(all_data['quick_adapt']==False)&(all_data['N']==5)]\n",
    "\n",
    "plot_4_data = all_data[(all_data['MAMLCon']==False)&(all_data['quick_adapt']==True)&(all_data['N']==5)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.lineplot(x='group', y='accuracy', data=plot_1_data.groupby('group').mean(), ax=ax1, color='black', linewidth=3)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(plot_1_data.groupby('group').mean().reset_index()['accuracy'], label='MAMLCon QA');\n",
    "plt.plot(plot_2_data.groupby('group').mean().reset_index()['accuracy'], label='Normal QA');\n",
    "plt.plot(plot_3_data.groupby('group').mean().reset_index()['accuracy'], label='MAMLCon');\n",
    "plt.plot(plot_4_data.groupby('group').mean().reset_index()['accuracy'], label='Normal');\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[(all_data['MAMLCon']==True)&(all_data['quick_adapt']==True)&(all_data['N']==5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.N.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flickr2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a43d7b48dfb8db078ab7642bd2e0d3611ffe6518b405d3c07c6468471a4b930"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
