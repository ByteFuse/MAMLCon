{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly_express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../data/training_results.csv')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_df_1 = df[(df.n_way==50)&(df.n_class_additions==5)&(df.n_classes_start==5)&(df.algorithm=='FSCL')&(df.dataset=='flickr8k')].\\\n",
    "#     drop(columns=['Name']).groupby(['k_shot']).max().reset_index(drop=False)\n",
    "# plot_df_2 = df[(df.n_way==10)&(df.n_class_additions==1)&(df.n_classes_start==2)&(df.algorithm=='FSCL')&(df.dataset=='google_commands')].\\\n",
    "#     drop(columns=['Name']).groupby(['k_shot']).max().reset_index(drop=False)\n",
    "# plot_df = pd.concat([plot_df_1, plot_df_2])\n",
    "\n",
    "# def rename_(name):\n",
    "#     if name == 'flickr8k':\n",
    "#         return 'Flickr8k: N=50, CA=5, CS=5'\n",
    "#     else:\n",
    "#         return \"Google Commands: N=10, CA=2, CS=2\"\n",
    "\n",
    "# plot_df['dataset']=plot_df['dataset'].apply(rename_)\n",
    "# plot_df.rename(columns={'k_shot':'K-Shot', 'validation_query_accuracy_epoch':'Final Accuracy', 'dataset':'Dataset'}, inplace=True)\n",
    "\n",
    "# plt.figure(figsize=(20, 10))\n",
    "# # set colours allowed to use to certain hex value\n",
    "# sns.set_palette(sns.color_palette([\"#1D2140\", \"#17C37B\"])) \n",
    "# sns.barplot(x='K-Shot', y='Final Accuracy', hue='Dataset', data=plot_df)\n",
    "# #add the value on top of the bar\n",
    "# for p in plt.gca().patches:\n",
    "#     plt.gca().text(p.get_x() + p.get_width()/2., p.get_height(), '{:1.2f}'.format(p.get_height()*100), fontsize=18, color='black', ha='center', va='bottom')\n",
    "\n",
    "# # make the legend text bigger\n",
    "# plt.legend(loc='lower right', prop={'size': 20})\n",
    "# # make plot font size bigger\n",
    "# plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "# # remove top grid line\n",
    "# plt.gca().spines['top'].set_visible(False)\n",
    "# plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "# plt.savefig('k_shot_accuracy.png', transparent=True, pad_inches=.2, frameon=False)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import WordClassificationAudio2DCnn, WordClassificationAudioCnnPool as WordClassificationAudioCnn, WordClassificationRnn\n",
    "from src.losses import ClassificationLoss\n",
    "from src.algorithms import FSCL, OML\n",
    "from src.data.datasets import Flickr8kWordClassification, GoogleCommandsWordClassification\n",
    "from src.data.samplers import SpokenWordTaskBatchSampler\n",
    "from src.utils import flatten_dict\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = {\n",
    "'name': 'adam',\n",
    "'inner_steps': 5,\n",
    "'val_inner_steps': 5,\n",
    "'gradient_clip_val': 0,\n",
    "'inner_learning_rate': 0.001,\n",
    "'outer_learning_rate': 0.0001,\n",
    "'scheduler': False,\n",
    "'scheduler_step': 30,\n",
    "'scheduler_decay': 0.1,\n",
    "}\n",
    "\n",
    "encoder = WordClassificationAudio2DCnn(\n",
    "    256, \n",
    "    64, \n",
    "    input_channels=39\n",
    ")\n",
    "\n",
    "class FSCLModel(nn.Module):\n",
    "    def __init__(self, encoder, embedding_dim, n_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "\n",
    "        def return_classification_layer(embedding_dim):\n",
    "            layer = nn.Linear(embedding_dim, 1)\n",
    "            torch.nn.init.xavier_uniform(layer.weight, )\n",
    "            layer = nn.Sequential(\n",
    "                nn.ReLU(),\n",
    "                layer\n",
    "            )\n",
    "            return layer\n",
    "\n",
    "        layers = [return_classification_layer(embedding_dim) for _ in range(n_classes)]\n",
    "        self.classifiers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, audio, total_classes_present):\n",
    "        features = self.encoder(audio)\n",
    "        layer_logits = []\n",
    "        for c_layer in range(total_classes_present):\n",
    "            layer_logits.append(self.classifiers[c_layer](features))\n",
    "        logits = torch.cat(layer_logits, dim=1)\n",
    "        return {'logits':logits}\n",
    "\n",
    "\n",
    "loss_fn = ClassificationLoss()\n",
    "\n",
    "model = FSCLModel(encoder, 256, 50)\n",
    "algorithm = FSCL.load_from_checkpoint(\n",
    "    './nway50_k5.ckpt', \n",
    "    model=model, \n",
    "    training_steps=5,\n",
    "    intial_training_steps=30,\n",
    "    n_classes_start=5,\n",
    "    n_class_additions=5,\n",
    "    loss_func=loss_fn,\n",
    "    optim_config=optim,\n",
    "    k_shot=5,\n",
    "    quick_adapt=True\n",
    ")\n",
    "model = algorithm.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/ruanv/Desktop/speech-fewshot-cl/data/flickr/flickr8k_word_splits_validation.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('../config/conversion_method/mfcc.yaml') as f:\n",
    "    conv_config = yaml.safe_load(f) \n",
    "\n",
    "valiadation_dataset = Flickr8kWordClassification(\n",
    "    meta_path='C:/Users/ruanv/Desktop/speech-fewshot-cl/data/flickr/flickr8k_word_splits_validation.csv',\n",
    "    audio_root='C:/Users/ruanv/Desktop/speech-fewshot-cl/data/flickr/wavs/', \n",
    "    conversion_config=conv_config,\n",
    "    stemming=True, \n",
    "    lemmetise=False          \n",
    ")\n",
    "\n",
    "\n",
    "def pad_audio(x, max_audio_len=101, pad_both_sides=False):\n",
    "    import torch.nn.functional as F\n",
    "    if x.size(-1) > max_audio_len:\n",
    "        x = x[:,:max_audio_len]\n",
    "    else:\n",
    "        if pad_both_sides:\n",
    "            pad_lenght = int(max_audio_len-x.size(-1))//2\n",
    "            x = F.pad(x, (pad_lenght, pad_lenght+1 if int(max_audio_len-x.size(-1))%2!=0 else pad_lenght), 'constant', 0)\n",
    "        else:\n",
    "            x = F.pad(x, (0, int(max_audio_len-x.size(-1))), 'constant', 0)\n",
    "    return x\n",
    "\n",
    "df = pd.read_csv('C:/Users/ruanv/Desktop/speech-fewshot-cl/data/flickr/flickr8k_word_splits_validation.csv')\n",
    "words_keep = [\n",
    "'surf', 'wave', 'crowd', 'fight', 'togeth', 'ski',\n",
    "'bridg', 'wood', 'teenag', 'lot', 'mud', 'pool', 'tabl', 'out',\n",
    "'wet', 'footbal', 'make', 'team', 'shop', 'their', 'edg', 'guitar',\n",
    "'across', 'area', 'do', 'trick', 'bike', 'obstacl', 'tri', 'rider',\n",
    "'track', 'room', 'him', 'jacket', 'glass', 'open', 'them', 'cap',\n",
    "'color', 'set', 'pant', 'wrestl', 'basketbal', 'climber', 'face',\n",
    "'mountain', 'tent', 'shore', 'ground', 'bar'\n",
    "]\n",
    "df = df[df.stem.isin(words_keep)]\n",
    "\n",
    "# sample 5 instances of each stem\n",
    "df = df.groupby('stem').apply(lambda x: x.sample(5)).reset_index(drop=True)\n",
    "df.to_csv('./plot_data_words.csv', index=False)\n",
    "\n",
    "\n",
    "valiadation_dataset = Flickr8kWordClassification(\n",
    "    meta_path='plot_data_words.csv',\n",
    "    audio_root='C:/Users/ruanv/Desktop/speech-fewshot-cl/data/flickr/wavs/', \n",
    "    conversion_config=conv_config,\n",
    "    stemming=True, \n",
    "    lemmetise=False          \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group every 25 instances together from validation set\n",
    "N = 5\n",
    "STEPS = 5*N\n",
    "\n",
    "\n",
    "groups = []\n",
    "test_groups = []\n",
    "\n",
    "for i in range(0, len(valiadation_dataset), STEPS):\n",
    "    arrays = []\n",
    "    labels = []\n",
    "\n",
    "    for j in range(0+i, STEPS+i):\n",
    "        arrays.append(pad_audio(torch.tensor(valiadation_dataset[j][0])).unsqueeze(0))\n",
    "        labels.append(torch.tensor(valiadation_dataset[j][1]))\n",
    "    \n",
    "    arrays = torch.concat(arrays,dim=0)\n",
    "\n",
    "    # take every 5th instance as test\n",
    "    test_arrays = arrays[::5]\n",
    "    test_labels = labels[::5]\n",
    "\n",
    "    # skip every 5th instance\n",
    "    arrays = torch.concat([array.unsqueeze(0) for i, array in enumerate(arrays) if i%5!=0 or i==0],dim=0)\n",
    "    labels = [label for i, label in enumerate(labels) if i%5!=0 or i==0]\n",
    "\n",
    "    groups.append({'data':arrays, 'labels':labels})\n",
    "    test_groups.append({'data':test_arrays, 'labels':test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "model = FSCLModel(encoder, 256, 50)\n",
    "algorithm = FSCL.load_from_checkpoint(\n",
    "    './nway50_k5.ckpt', \n",
    "    model=model, \n",
    "    training_steps=5,\n",
    "    intial_training_steps=30,\n",
    "    n_classes_start=5,\n",
    "    n_class_additions=5,\n",
    "    loss_func=loss_fn,\n",
    "    optim_config=optim,\n",
    "    k_shot=5,\n",
    "    quick_adapt=True\n",
    ")\n",
    "model = algorithm.model\n",
    "\n",
    "criterion = ClassificationLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "for n, group in enumerate(groups):\n",
    "    model.train()\n",
    "    data, labels = group['data'], group['labels']\n",
    "    for i in range(50):\n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(data, (n+1)*N)\n",
    "        outputs['labels'] = torch.tensor(labels)\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "    # Print loss for each epoch\n",
    "    print(f'Training loss: {loss.item():.4f}')\n",
    "\n",
    "    # for group in groups[:n+1]:\n",
    "    #     data, labels = group['data'], group['labels']\n",
    "    #     optimizer.zero_grad()\n",
    "\n",
    "    #     # take every 5th instance\n",
    "    #     data = data[::5]\n",
    "    #     labels = labels[::5]\n",
    "\n",
    "    #     # Forward pass\n",
    "    #     outputs = model(data, (n+1)*N)\n",
    "    #     outputs['labels'] = torch.tensor(labels)\n",
    "    #     # Compute loss\n",
    "    #     loss = criterion(outputs)\n",
    "        \n",
    "    #     # Backward pass and optimization\n",
    "    #     loss.backward()\n",
    "    #     optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        for i, group in enumerate(test_groups[:n+1]):\n",
    "            data, labels = group['data'], group['labels']\n",
    "            outputs = model(data, (i+1)*N)\n",
    "            outputs['labels'] = torch.tensor(labels)\n",
    "            loss = criterion(outputs)\n",
    "\n",
    "            predicted_labels = torch.argmax(outputs['logits'], dim=1)\n",
    "            accuracy = torch.sum(predicted_labels == torch.tensor(labels)).item() / len(labels)\n",
    "\n",
    "            # print(f'Test loss for group {i}, after training group {n}: {loss.item():.4f}')\n",
    "            # print(f'Test accuracy for group {i}, after training group {n}: {accuracy:.4f}') \n",
    "            # print('---')\n",
    "\n",
    "            results = pd.concat([results,pd.DataFrame({'loss':[loss.item()], 'accuracy':[accuracy], 'group':[i], 'training_group':[n]})])\n",
    "            results.to_csv('group_averages_MAMLCon_no_update.csv', index=False)\n",
    "\n",
    "    # print('*'*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.barplot(x='group', y='accuracy', hue='training_group', data=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_model = FSCLModel(encoder, 256, 50)\n",
    "results = pd.DataFrame()\n",
    "\n",
    "criterion = ClassificationLoss()\n",
    "optimizer = torch.optim.Adam(t_model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "for n, group in enumerate(groups):\n",
    "    t_model.train()\n",
    "    data, labels = group['data'], group['labels']\n",
    "    for i in range(50):\n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = t_model(data, (n+1)*N)\n",
    "        outputs['labels'] = torch.tensor(labels)\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "    # Print loss for each epoch\n",
    "    print(f'Training loss: {loss.item():.4f}')\n",
    "\n",
    "    for group in groups[:n+1]:\n",
    "        data, labels = group['data'], group['labels']\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # take every 5th instance\n",
    "        data = data[::5]\n",
    "        labels = labels[::5]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = t_model(data, (n+1)*N)\n",
    "        outputs['labels'] = torch.tensor(labels)\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        t_model.eval()\n",
    "\n",
    "        for i, group in enumerate(test_groups[:n+1]):\n",
    "            data, labels = group['data'], group['labels']\n",
    "            outputs = t_model(data, (i+1)*N)\n",
    "            outputs['labels'] = torch.tensor(labels)\n",
    "            loss = criterion(outputs)\n",
    "\n",
    "            predicted_labels = torch.argmax(outputs['logits'], dim=1)\n",
    "            accuracy = torch.sum(predicted_labels == torch.tensor(labels)).item() / len(labels)\n",
    "\n",
    "            # print(f'Test loss for group {i}, after training group {n}: {loss.item():.4f}')\n",
    "            # print(f'Test accuracy for group {i}, after training group {n}: {accuracy:.4f}') \n",
    "            # print('---')\n",
    "\n",
    "            results = pd.concat([results,pd.DataFrame({'loss':[loss.item()], 'accuracy':[accuracy], 'group':[i], 'training_group':[n]})])\n",
    "            results.to_csv('group_averages.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flickr2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a43d7b48dfb8db078ab7642bd2e0d3611ffe6518b405d3c07c6468471a4b930"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
